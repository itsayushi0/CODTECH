{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMx7y2/Rp0sfgFlz+JpW44u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itsayushi0/CODTECH/blob/main/task3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"\n",
        "Task-3: NLP Chatbot with spaCy & scikit-learn\n",
        "---------------------------------------------\n",
        "This notebook builds a simple FAQ chatbot using:\n",
        "- spaCy for text preprocessing (lemmatization, stopword removal)\n",
        "- TF-IDF + cosine similarity for question matching\n",
        "- Rule-based replies for small talk (hello, thanks, bye)\n",
        "\n",
        "Run cells in order, then use the chat loop at the bottom.\n",
        "\n",
        "How to use:\n",
        "1. Run dependency install (Cell 2)\n",
        "2. Edit FAQs (Cell 3) to your needs\n",
        "3. Run the chatbot logic (Cell 4)\n",
        "4. Interact with the chatbot (Cell 5)\n",
        "\n",
        "Author:Ayushi pal\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "edZoM7wIn1ZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy scikit-learn\n",
        "!python -m spacy download en_core_web_sm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2P6jlKKn5ER",
        "outputId": "42a4491d-1c3c-41fc-8fdf-65511766b8e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.8.3)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# questions\n",
        "faqs = [\n",
        "    {\"question\": \"What is your name?\", \"answer\": \"I am a simple NLP chatbot.\"},\n",
        "    {\"question\": \"How do I submit internship tasks?\", \"answer\": \"Push your code to GitHub and follow the WhatsApp video guidance.\"},\n",
        "    {\"question\": \"Which NLP library do you use?\", \"answer\": \"I use spaCy for text processing.\"},\n",
        "    {\"question\": \"How can I contact support?\", \"answer\": \"Post in the WhatsApp group or email the coordinator.\"}\n",
        "]\n"
      ],
      "metadata": {
        "id": "xJzft1-zojXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Lemmatizer function\n",
        "def spacy_lemmas(text):\n",
        "    doc = nlp(text.lower())\n",
        "    return \" \".join(\n",
        "        tok.lemma_ for tok in doc\n",
        "        if not tok.is_stop and not tok.is_punct and not tok.like_num and tok.lemma_.strip()\n",
        "    )\n",
        "\n",
        "# Prepare data\n",
        "questions = [item[\"question\"] for item in faqs]\n",
        "answers = [item[\"answer\"] for item in faqs]\n",
        "\n",
        "vectorizer = TfidfVectorizer(preprocessor=spacy_lemmas)\n",
        "q_matrix = vectorizer.fit_transform(questions)\n",
        "\n",
        "# Rule-based small talk\n",
        "RULES = {\n",
        "    (\"hi\", \"hello\", \"hey\"): \"Hello! How can I help you today?\",\n",
        "    (\"thanks\", \"thank you\"): \"You're welcome!\",\n",
        "    (\"bye\", \"goodbye\"): \"Bye! Have a great day.\"\n",
        "}\n",
        "\n",
        "def rule_based_reply(user_text):\n",
        "    t = user_text.lower().strip()\n",
        "    for triggers, reply in RULES.items():\n",
        "        if any(k in t for k in triggers):\n",
        "            return reply\n",
        "    return None\n",
        "\n",
        "# Chatbot answer function\n",
        "SIM_THRESHOLD = 0.35  # tune this if needed\n",
        "\n",
        "def answer_query(user_text):\n",
        "    rb = rule_based_reply(user_text)\n",
        "    if rb:\n",
        "        return rb\n",
        "\n",
        "    u_vec = vectorizer.transform([user_text])\n",
        "    sims = cosine_similarity(u_vec, q_matrix).flatten()\n",
        "    best_idx = sims.argmax()\n",
        "    best_score = sims[best_idx]\n",
        "\n",
        "    if best_score >= SIM_THRESHOLD:\n",
        "        return answers[best_idx]\n",
        "    else:\n",
        "        return \"Sorry, I‚Äôm not sure about that yet.\"\n"
      ],
      "metadata": {
        "id": "-1wFs2IDovOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"NLP Chatbot ready. Type 'quit' to exit.\")\n",
        "while True:\n",
        "    user = input(\"You: \")\n",
        "    if user.lower() in {\"quit\", \"exit\"}:\n",
        "        print(\"Bot: Goodbye!\")\n",
        "        break\n",
        "    print(\"Bot:\", answer_query(user))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7SuETuRpLjO",
        "outputId": "2da38db2-52c9-4230-bab8-80fc4fcd5295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLP Chatbot ready. Type 'quit' to exit.\n",
            "You: quit\n",
            "Bot: Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages (quiet mode)\n",
        "!pip install streamlit > /dev/null\n",
        "!npm install -g localtunnel > /dev/null\n",
        "\n",
        "# Save chatbot logic into a Python file\n",
        "with open(\"chatbot_logic.py\", \"w\") as f:\n",
        "    f.write('''\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "faqs = [\n",
        "    {\"question\": \"What is your name?\", \"answer\": \"I am a simple NLP chatbot.\"},\n",
        "    {\"question\": \"How do I submit internship tasks?\", \"answer\": \"Push your code to GitHub and follow the WhatsApp video guidance.\"},\n",
        "    {\"question\": \"Which NLP library do you use?\", \"answer\": \"I use spaCy for text processing.\"},\n",
        "    {\"question\": \"How can I contact support?\", \"answer\": \"Post in the WhatsApp group or email the coordinator.\"}\n",
        "]\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def spacy_lemmas(text):\n",
        "    doc = nlp(text.lower())\n",
        "    return \" \".join(\n",
        "        tok.lemma_ for tok in doc\n",
        "        if not tok.is_stop and not tok.is_punct and not tok.like_num and tok.lemma_.strip()\n",
        "    )\n",
        "\n",
        "questions = [item[\"question\"] for item in faqs]\n",
        "answers = [item[\"answer\"] for item in faqs]\n",
        "\n",
        "vectorizer = TfidfVectorizer(preprocessor=spacy_lemmas)\n",
        "q_matrix = vectorizer.fit_transform(questions)\n",
        "\n",
        "RULES = {\n",
        "    (\"hi\", \"hello\", \"hey\"): \"Hello! How can I help you today?\",\n",
        "    (\"thanks\", \"thank you\"): \"You're welcome!\",\n",
        "    (\"bye\", \"goodbye\"): \"Bye! Have a great day.\"\n",
        "}\n",
        "\n",
        "def rule_based_reply(user_text):\n",
        "    t = user_text.lower().strip()\n",
        "    for triggers, reply in RULES.items():\n",
        "        if any(k in t for k in triggers):\n",
        "            return reply\n",
        "    return None\n",
        "\n",
        "SIM_THRESHOLD = 0.35\n",
        "\n",
        "def answer_query(user_text):\n",
        "    rb = rule_based_reply(user_text)\n",
        "    if rb:\n",
        "        return rb\n",
        "\n",
        "    u_vec = vectorizer.transform([user_text])\n",
        "    sims = cosine_similarity(u_vec, q_matrix).flatten()\n",
        "    best_idx = sims.argmax()\n",
        "    best_score = sims[best_idx]\n",
        "\n",
        "    if best_score >= SIM_THRESHOLD:\n",
        "        return answers[best_idx]\n",
        "    else:\n",
        "        return \"Sorry, I‚Äôm not sure about that yet.\"\n",
        "''')\n",
        "\n",
        "# Create a simple Streamlit app\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write('''\n",
        "import streamlit as st\n",
        "from chatbot_logic import answer_query\n",
        "\n",
        "st.set_page_config(page_title=\"NLP Chatbot\", page_icon=\"ü§ñ\")\n",
        "\n",
        "st.title(\"üí¨ NLP Chatbot\")\n",
        "st.markdown(\"Ask me a question and I'll try my best to answer.\")\n",
        "\n",
        "user_input = st.text_input(\"You:\", \"\")\n",
        "\n",
        "if st.button(\"Send\"):\n",
        "    if user_input.strip():\n",
        "        reply = answer_query(user_input)\n",
        "        st.write(f\"**Bot:** {reply}\")\n",
        "    else:\n",
        "        st.warning(\"Please type something before sending.\")\n",
        "''')\n",
        "\n",
        "# Run Streamlit and expose via localtunnel\n",
        "!streamlit run app.py --server.port 8501 & npx localtunnel --port 8501\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ne-5rts05ge",
        "outputId": "00196e30-f9da-407f-93e2-8d2cb815d174"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.9.217.194:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0Kyour url is: https://fresh-apes-smoke.loca.lt\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}